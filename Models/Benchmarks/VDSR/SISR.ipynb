{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SISR.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1G5cv0UuZPiAG-WeSaZEdE_mD82O3mZjM","authorship_tag":"ABX9TyPogMgWnMJ1oEe2bXkwcZbh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"IlLHSExu-g2r","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638181752976,"user_tz":-330,"elapsed":3666,"user":{"displayName":"jhansi mallela","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhucAyLm-FCq0hpK3OOo1kUkQOVBWxw4ie3mxDM=s64","userId":"06998838605736096564"}},"outputId":"4b261692-d0d9-4697-da94-06a089e7bae1"},"source":["import h5py\n","filename = \"/content/drive/MyDrive/IIIT_Hyd/Jhansi/Monsoon2021/SMAI/project/traindiv2k.h5\"\n","\n","with h5py.File(filename, \"r\") as f:\n","    # List all groups\n","    print(\"Keys: %s\" % f.keys())\n","    a_group_key = list(f.keys())[0]\n","    b_group_key = list(f.keys())[1]\n","\n","    # Get the data\n","    datas = list(f[a_group_key])\n","    labelss = list(f[b_group_key])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Keys: <KeysViewHDF5 ['data', 'label']>\n"]}]},{"cell_type":"code","metadata":{"id":"DZ5q8qaLuiIN","colab":{"base_uri":"https://localhost:8080/","height":201},"executionInfo":{"status":"error","timestamp":1638194071172,"user_tz":-330,"elapsed":2093,"user":{"displayName":"jhansi mallela","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhucAyLm-FCq0hpK3OOo1kUkQOVBWxw4ie3mxDM=s64","userId":"06998838605736096564"}},"outputId":"2b4c6d8e-79bb-4b23-a684-afdb0abc4e75"},"source":["import numpy as np\n","train = np.array(data)\n","train.shape"],"execution_count":2,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-260ebb4b5296>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"]}]},{"cell_type":"code","metadata":{"id":"gJKiAdZ0GtJf","executionInfo":{"status":"ok","timestamp":1638194109840,"user_tz":-330,"elapsed":6436,"user":{"displayName":"jhansi mallela","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhucAyLm-FCq0hpK3OOo1kUkQOVBWxw4ie3mxDM=s64","userId":"06998838605736096564"}}},"source":["import argparse, os\n","import torch\n","import random\n","import torch.nn as nn\n","import torch.optim as optim\n","from math import sqrt\n","from torch.utils.data import DataLoader\n","import h5py\n","from torch.autograd import Variable"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"AlnKA7zoImXs","executionInfo":{"status":"ok","timestamp":1638194115272,"user_tz":-330,"elapsed":610,"user":{"displayName":"jhansi mallela","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhucAyLm-FCq0hpK3OOo1kUkQOVBWxw4ie3mxDM=s64","userId":"06998838605736096564"}}},"source":["class Conv_ReLU_Block(nn.Module):\n","    def __init__(self):\n","        super(Conv_ReLU_Block, self).__init__()\n","        self.conv = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.relu = nn.ReLU(inplace=True)\n","        \n","    def forward(self, x):\n","        return self.relu(self.conv(x))\n","        \n","class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.residual_layer = self.make_layer(Conv_ReLU_Block, 18)\n","        self.input = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.output = nn.Conv2d(in_channels=64, out_channels=1, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.relu = nn.ReLU(inplace=True)\n","    \n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n","                m.weight.data.normal_(0, sqrt(2. / n))\n","                \n","    def make_layer(self, block, num_of_layer):\n","        layers = []\n","        for _ in range(num_of_layer):\n","            layers.append(block())\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        residual = x\n","        out = self.relu(self.input(x))\n","        out = self.residual_layer(out)\n","        out = self.output(out)\n","        out = torch.add(out,residual)\n","        return out\n"," "],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"huhLLjr5I6GF","executionInfo":{"status":"ok","timestamp":1638194126359,"user_tz":-330,"elapsed":580,"user":{"displayName":"jhansi mallela","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhucAyLm-FCq0hpK3OOo1kUkQOVBWxw4ie3mxDM=s64","userId":"06998838605736096564"}}},"source":["\n","# Training settings\n","batchSize=128\n","nEpochs=1         #\"Number of epochs to train for\")\n","lr=0.1            #\"Learning Rate. Default=0.1\")\n","step=10           #\"Sets the learning rate to the initial LR decayed by momentum every n epochs, Default: n=10\")\n","momentum=0.9      #\"Momentum, Default: 0.9\")\n","weight_decay=1e-4  #\"Weight decay, Default: 1e-4\")\n","clip=0.4"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"uREoHK65M2eW","executionInfo":{"status":"ok","timestamp":1638194135512,"user_tz":-330,"elapsed":595,"user":{"displayName":"jhansi mallela","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhucAyLm-FCq0hpK3OOo1kUkQOVBWxw4ie3mxDM=s64","userId":"06998838605736096564"}}},"source":["import torch.utils.data as data\n","class DatasetFromHdf5(data.Dataset):\n","    def __init__(self, file_path):\n","        super(DatasetFromHdf5, self).__init__()\n","        hf = h5py.File(file_path)\n","        self.data = hf.get('data')\n","        self.target = hf.get('label')\n","\n","    def __getitem__(self, index):\n","        return torch.from_numpy(self.data[index,:,:,:]).float(), torch.from_numpy(self.target[index,:,:,:]).float()\n","        \n","    def __len__(self):\n","        return self.data.shape[0]"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L-QAZfsGJPjf","executionInfo":{"status":"ok","timestamp":1638194777815,"user_tz":-330,"elapsed":628156,"user":{"displayName":"jhansi mallela","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhucAyLm-FCq0hpK3OOo1kUkQOVBWxw4ie3mxDM=s64","userId":"06998838605736096564"}},"outputId":"1ad985bc-f996-4380-aec3-2f54f6fc9053"},"source":["\n","def main():\n","    \n","\n","    print(\"===> Loading datasets\")\n","    \n","    train_set = DatasetFromHdf5(\"/content/drive/MyDrive/IIIT_Hyd/Jhansi/Monsoon2021/SMAI/project/traindiv2k.h5\")\n","    training_data_loader = DataLoader(dataset=train_set,  batch_size=batchSize, shuffle=True)\n","\n","    print(\"===> Building model\")\n","    model = Net()\n","    criterion = nn.MSELoss(size_average=False)\n","\n","    print(\"===> Setting Optimizer\")\n","    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n","\n","    print(\"===> Training\")\n","    for epoch in range(1, nEpochs + 1):\n","        train(training_data_loader, optimizer, model, criterion, epoch)\n","        save_checkpoint(model, epoch)\n","\n","def adjust_learning_rate(optimizer, epoch):\n","    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 10 epochs\"\"\"\n","    lr = 0.1 * (0.1 ** (epoch // step))\n","    return lr\n","\n","def train(training_data_loader, optimizer, model, criterion, epoch):\n","    lr = adjust_learning_rate(optimizer, epoch-1)\n","\n","    for param_group in optimizer.param_groups:\n","        param_group[\"lr\"] = lr\n","\n","    print(\"Epoch = {}, lr = {}\".format(epoch, optimizer.param_groups[0][\"lr\"]))\n","\n","    model.train()\n","\n","    for iteration, batch in enumerate(training_data_loader, 1):\n","        input, target = Variable(batch[0]), Variable(batch[1], requires_grad=False)\n","\n","        loss = criterion(model(input), target)\n","        optimizer.zero_grad()\n","        loss.backward() \n","        nn.utils.clip_grad_norm(model.parameters(),clip) \n","        optimizer.step()\n","\n","        if iteration%100 == 0:\n","            print(\"===> Epoch[{}]({}/{}): Loss: {:.10f}\".format(epoch, iteration, len(training_data_loader), loss.data[0]))\n","\n","def save_checkpoint(model, epoch):\n","    model_out_path = \"checkpoint/\" + \"model_epoch_{}.pth\".format(epoch)\n","    state = {\"epoch\": epoch ,\"model\": model}\n","    if not os.path.exists(\"checkpoint/\"):\n","        os.makedirs(\"checkpoint/\")\n","\n","    torch.save(state, model_out_path)\n","\n","    print(\"Checkpoint saved to {}\".format(model_out_path))\n","\n","if __name__ == \"__main__\":\n","    main()"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["===> Loading datasets\n","===> Building model\n","===> Setting Optimizer\n","===> Training\n","Epoch = 1, lr = 0.1\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n","  warnings.warn(warning.format(ret))\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:43: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"]},{"output_type":"stream","name":"stdout","text":["Checkpoint saved to checkpoint/model_epoch_1.pth\n"]}]}]}